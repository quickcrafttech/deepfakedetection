{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle\n",
        "\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "d8Zw7JUw4VB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt user to upload kaggle.json file\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Check if file is uploaded\n",
        "if 'kaggle.json' not in uploaded.keys():\n",
        "  print(\"Error: Upload the kaggle.json file for authentication!\")\n",
        "else:\n",
        "  # Move the uploaded file to the expected location\n",
        "  !mkdir -p ~/.kaggle\n",
        "  !cp {uploaded['kaggle.json']['name']} ~/.kaggle/kaggle.json\n",
        "\n",
        "  # Set permissions for the kaggle.json file\n",
        "  !chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "  # Print confirmation message\n",
        "  print(\"kaggle.json uploaded successfully!\")"
      ],
      "metadata": {
        "id": "_SO1JU6b41QP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download data from kaggle\n",
        "print(\"Downloading data from Kaggle...\")\n",
        "!kaggle datasets download -d tusharpadhy/deepfake-dataset"
      ],
      "metadata": {
        "id": "aSnp-Qx34reG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJQkMqjy4P52"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
        "from keras import backend as K"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KjXmykd74P57"
      },
      "outputs": [],
      "source": [
        "# Define constants\n",
        "IMAGE_SIZE = (128, 128)\n",
        "BATCH_SIZE = 4\n",
        "NUM_CLASSES = 2\n",
        "EPOCHS = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QFxOuj174P58"
      },
      "outputs": [],
      "source": [
        "# Define directories\n",
        "train_dir = '../dataset_2/train'\n",
        "valid_dir = '../dataset_2/valid'\n",
        "test_dir = '../dataset_2/test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5x5isWRT4P59"
      },
      "outputs": [],
      "source": [
        "# Use ImageDataGenerator for data augmentation and normalization\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9iypT8i4P59",
        "outputId": "af945fea-fb53-4d9b-8a25-bb739115129e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 240002 images belonging to 2 classes.\n",
            "Found 59428 images belonging to 2 classes.\n",
            "Found 30905 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "# Flow images from directories\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    valid_dir,\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KC7ngGpK4P5-"
      },
      "outputs": [],
      "source": [
        "# Define the model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qSV2MdXN4P6C"
      },
      "outputs": [],
      "source": [
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tj2xLp1Y4P6E"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy',f1_m,precision_m, recall_m])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "am4HVT4W4P6L"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
        "    epochs=20,\n",
        "    validation_data=valid_generator,\n",
        "    validation_steps=valid_generator.samples // BATCH_SIZE\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHxZJvJM4P6M"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "test_loss, test_acc, test_precision, test_recall, test_f1 = model.evaluate(test_generator, steps=test_generator.samples // BATCH_SIZE)\n",
        "print('Test accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PapsMrlM4P6N"
      },
      "outputs": [],
      "source": [
        "# Extract metrics from history object\n",
        "train_acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "train_precision = history.history['precision_m']\n",
        "val_precision = history.history['val_precision_m']\n",
        "train_recall = history.history['recall_m']\n",
        "val_recall = history.history['val_recall_m']\n",
        "train_f1 = history.history['f1_m']\n",
        "val_f1 = history.history['val_f1_m']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3rf76zkK4P6N"
      },
      "outputs": [],
      "source": [
        "# Plot accuracy graph\n",
        "plt.plot(history.epoch, train_acc, label='Train Accuracy')\n",
        "plt.plot(history.epoch, val_acc, label='Validation Accuracy')\n",
        "plt.plot([1], test_acc, label='Test Accuracy', marker='o')  # Test accuracy as a single point\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bX2cWY644P6N"
      },
      "outputs": [],
      "source": [
        "# Plot precision, recall, and f1-score graphs (similar to accuracy graph)\n",
        "plt.plot(history.epoch, train_precision, label='Train Precision')\n",
        "plt.plot(history.epoch, val_precision, label='Validation Precision')\n",
        "plt.plot([1], test_precision, label='Test Precision', marker='o')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Precision')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iO6dkbOV4P6N"
      },
      "outputs": [],
      "source": [
        "# Plot recall graph\n",
        "plt.plot(history.epoch, train_recall, label='Train Recall')\n",
        "plt.plot(history.epoch, val_recall, label='Validation Recall')\n",
        "plt.plot([1], test_recall, label='Test Recall', marker='o')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Recall')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WcNivfM14P6O"
      },
      "outputs": [],
      "source": [
        "# Plot f1-score graph\n",
        "plt.plot(history.epoch, train_f1, label='Train F1-score')\n",
        "plt.plot(history.epoch, val_f1, label='Validation F1-score')\n",
        "plt.plot([1], test_f1, label='Test F1-score', marker='o')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('F1-score')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HV9JYvs24P6O"
      },
      "outputs": [],
      "source": [
        "# Get model predictions\n",
        "y_train_pred = model.predict(train_generator)\n",
        "y_val_pred = model.predict(valid_generator)\n",
        "y_test_pred = model.predict(test_generator)\n",
        "\n",
        "# Convert predictions to class labels (assuming binary classification)\n",
        "y_train_pred_classes = [int(pred >= 0.5) for pred in y_train_pred]\n",
        "y_val_pred_classes = [int(pred >= 0.5) for pred in y_val_pred]\n",
        "y_test_pred_classes = [int(pred >= 0.5) for pred in y_test_pred]\n",
        "\n",
        "# Get true class labels\n",
        "y_train_true = train_generator.classes\n",
        "y_val_true = valid_generator.classes\n",
        "y_test_true = test_generator.classes\n",
        "\n",
        "# Create confusion matrices\n",
        "cm_train = confusion_matrix(y_train_true, y_train_pred_classes)\n",
        "cm_val = confusion_matrix(y_val_true, y_val_pred_classes)\n",
        "cm_test = confusion_matrix(y_test_true, y_test_pred_classes)\n",
        "\n",
        "# Print confusion matrices\n",
        "print(\"Train Confusion Matrix:\\n\", cm_train)\n",
        "print(\"Validation Confusion Matrix:\\n\", cm_val)\n",
        "print(\"Test Confusion Matrix:\\n\", cm_test)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}